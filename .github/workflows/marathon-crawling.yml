name: Marathon Crawling Monthly Job

on:
  schedule:
    # 매월 1일 오전 9시 KST (= UTC 0시)
    - cron: '0 0 1 * *'
  workflow_dispatch: # 수동 실행 허용

jobs:
  crawl:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.13'
        cache: 'pip'

    - name: Install system dependencies (Chrome and ChromeDriver)
      run: |
        sudo apt-get update
        sudo apt-get install -y chromium-browser chromium-chromedriver
        sudo ln -sf /usr/lib/chromium-browser/chromedriver /usr/local/bin/chromedriver

    - name: Install Python dependencies
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt

    - name: Create .env file from secrets
      run: |
        echo "MYSQL_HOSTNAME=${{ secrets.MYSQL_HOSTNAME }}" >> .env
        echo "MYSQL_USER=${{ secrets.MYSQL_USER }}" >> .env
        echo "MYSQL_PASSWORD=${{ secrets.MYSQL_PASSWORD }}" >> .env
        echo "MYSQL_DATABASE=${{ secrets.MYSQL_DATABASE }}" >> .env
        echo "MYSQL_TABLE=${{ secrets.MYSQL_TABLE }}" >> .env
        echo "OPTION_ARGUMENTS=${{ secrets.OPTION_ARGUMENTS }}" >> .env
        echo "OUTPUT_CSV_FILE_NAME=${{ secrets.OUTPUT_CSV_FILE_NAME }}" >> .env
        echo "CHROMEDRIVER_PATH=/usr/lib/chromium-browser/chromedriver" >> .env

    - name: Run marathon crawling script
      run: python marathon-crawling.py

    - name: Upload CSV artifact (optional)
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: marathon-data
        path: '*.csv'
        retention-days: 30
